Title,Conference,Abstract,Image,Paper,Project,Code,Video,Authors
HumanOLAT- A Large-Scale Dataset for Full-Body Human Relighting and Novel-View Synthesis, International Conference for Computer Vision (ICCV) 2025, "We present HumanOLAT, the first public dataset with full-body humans captured in a custom-built lightstage using 331 programmable lights and 40 synchronized cameras. This setup enables high-resolution multi-view OLAT captures under diverse HDR lighting conditions, including white lights, color gradients, and environment maps. HumanOLAT sets a new standard for benchmarking relighting and novel-view synthesis on complex, real human appearances.",/assets/img/pub/olat.png,https://arxiv.org/pdf/208.07903.pdf,https://lvsn.github.io/PanoHDR-NeRF/,https://github.com/darthgera123/PanoHDR-NeRF,https://youtu.be/_mUeHePYQF8","Pulkit Gera, Timo Teufel, Xilong Zhou, Umar Iqbal, Pramod Rao, Jan Kautz, Vladislav Golyanik, Christian Theobalt"
Casual Indoor HDR Radiance Capture from Omnidirectional Images,British Machnine Vision Conference (BMVC) 2022,"We present PanoHDR-NeRF, a novel pipeline to casually capture a plausible full HDR radiance field of a large indoor scene without any elaborate setups or complex capture protocols. AN LDR2HDR network is trained to recover HDR light probes from casually captured omnidirectional LDR frames. It is then used to train PanoHDR-NeRF. Our pipeline can estimate full HDR panoramas from any location of the scene and can synthesize correct lighting effects which enable augmentation of indoor scenes with synthetic objects.",/assets/img/pub/panohdrnerf.jpg,https://arxiv.org/pdf/208.07903.pdf,https://lvsn.github.io/PanoHDR-NeRF/,https://github.com/darthgera123/PanoHDR-NeRF,https://youtu.be/_mUeHePYQF8,"Pulkit Gera, Mohammed Reza Karimi Dastjerdi,Charles Renaud, P.J Narayanan, Jean-Fran√ßois Lalonde"
Neural View Synthesis and Appearance Editing from Unstructured Images,Indian Conference on Computer Vision Graphics and Image Processing (ICVGIP) 2021 ,We present a neural rendering framework for simultaneous view synthesis and appearance editing of a scene with known environmental illumination captured using a mobile camera. Our approach explicitly disentangles the appearance and learns a lighting representation that is independent of it. We show results of editing the appearance of real scenes in interesting and non-trivial ways.,/assets/img/pub/app.png,https://dl.acm.org/doi/abs/10.1145/3490035.3490299,/appearance-editing/,https://github.com/darthgera123/Appearance-Editing,https://youtu.be/ZCVQj5FK0C4,"Pulkit Gera, Aakash.KT, Dhawal Sirikonda, P.J Narayanan"